# Сбой системы Github в 2018 году

**ОБЩАЯ СВОДКА ПО ИНЦИДЕНТУ**

Между 22:52-21/10/18 UTC и 23:03-22/10/18 UTC  весь функционал github частично перестал функционировать. Операции git push не проходили, репозитории не создавались, созданные pull request, Issue и записи комментариев к уже существующим Issue визуально отобража лись, а после перезагрузки — пропадали.

**ВВЕДЕНИЕ**

21 октября в 22:52 UTC проводились плановые работы по техническому обслуживанию для замены неисправного сетевого модуля в датацентре

---

**СБОЙ**

замена неисправного сетевого модуля привела к потере связности между датацентрами, повлекшей за собой нарушение целостности данных в MySQL и проблемам в работе некоторых сервисов. Связь между этими датацентрами была восстановлена через 43 секунды, но это короткое отключение вызвало цепочку событий, которые привели к 24 часам и 11 минутам деградации обслуживания.

---

**ОБНАРУЖЕНИЕ**

21 октября в 22:54 UTC внутренняя система мониторинга начала генерировать алерты об различных ошибках. В 23:02 UTC отвественные мониторинг инженеры установили, что топологии некоторых кластеров в состоянии сбоя.

---

**ВОССТАНОВЛЕНИЕ**

произведено восстановление данных MySQL из бэкапа, восстановлена репликация, восстановлена топология репликации, восстановлена работа выключенных сервисов.

---

**ТАЙМЛАЙН**

- `2018 21 октября 22:52 UTC` запланированная замена неисправного сетевого модуля привела к 43 секундной потере сетевой связности между двумя датацентрами. Orchestrator начинает аварийное переключение кластеров для направления операций записи в центр обработки данных на западном побережье США.
- `2018 21 октября 22:54 UTC` появились многочисленные алерты о сбоях в работе.
- `2018 21 октября 23:07 UTC` кластер был переведен в ручной режим управления топологией.
- `2018 21 октября 23:09 UTC` статус сайт переведен  в желтый статус
- `2018 21 октября 23:11 UTC` координатор инцидента изменил статус решения на красный
- `2018 21 октября 23:13 UTC` на этом этапе было обнаружено, что ни один из датацентров не содержит полной реплики данных. Вызваны дополнительные инженеры из группы разработки баз данных GitHub
- `2018 21 октября 23:19 UTC` чтобы обеспечить целостность данных, было принято решение об отключении некоторых служб: pages jobs, webhooks, pushes
- `2018 22 октября 00:05 UTC` разработан пошаговый план восстановления данных из бэкапа, восстановления топологии кластера и запуска остановленных сервисов. Информирование пользователей о ситуации
- `2018 22 октября 00:41 UTC` начат процесс восстановления ланных из бекапа . Поиск способов ускорить передачу и время восстановления
- `2018 22 октября 06:51 UTC` включили репликацию свежих данных после завершения восстановления из бэкапа. Значительный объем данных репликации между датацентрами увеличил время отклика на пользовательские запросы.
- `2018 22 октября 07:46 UTC` опубликовано сообщение в блоге , чтобы предоставить больше  информации пользователям
- `2018 22 октября 11:12 UTC` частично восстановлена правильная топология кластеров, 
- `2018 22 октября 13:15 UTC` пользовательская нагрузка достигла пиковых значений.  Время репликации уменьшается, из-за увеличенного количества реплик чтения.
- `2018 22 октября 16:24 UTC` полностью восстановлена топология кластеров. Выполнено аварийное переключение на исходную топологию
- `2018 22 октября 16:45 UTC` для восстановления работы notification сервисов была проведена дополнительная работа по балансировке дополнительной нагрузки, а также обновлены значения TTL для тех хуков, у которых истекло время 
- `2018 22 октября 23:03 UTC` работы по восстановлению завершены.

---

**ДЕЙСТВИЯ ПОСЛЕ ИНЦИДЕНТА**

ГитХаб предпринял ряд технических действий, таких как:

- добавлены новые настройки, предотвращающие фейловер write-нод в другой регион в целях избежания задержек записи;
- улучшена система коммуникации с пользователями в случае инцидентов;
- ускорена разработка архитектуры, способной выдерживать падение целого датацентра;
- улучшена процедура документирования, позволяющая донести цель и смысл тех или иных технических решений;
- внедрены процедуры анализа возможных сценариев сбоя
- принят ряд организационных инициатив, которые помогут в дальнейшем предотвратить повторение подобных ситуаций.
